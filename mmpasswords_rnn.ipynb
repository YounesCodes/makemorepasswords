{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abd3c862-e38b-47ad-8522-80aaacfa7ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first couple of cells are the same as previous notebooks\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "432443d5-8211-4e10-84ab-cf3db43fe110",
   "metadata": {},
   "outputs": [],
   "source": [
    "passwords = open('rockyou.txt', 'r',encoding='latin1').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31683966-cd52-4e54-a475-20d52e440368",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed = set(\"abcdefghijklmnopqrstuvwxyz0123456789\") # for simplification\n",
    "filtered_passwords = []\n",
    "for p in passwords:\n",
    "    if all(char in allowed for char in p):\n",
    "        filtered_passwords.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5092be1-6504-41c6-aedc-e0f5d19e2166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 0,\n",
       " '0': 1,\n",
       " '1': 2,\n",
       " '2': 3,\n",
       " '3': 4,\n",
       " '4': 5,\n",
       " '5': 6,\n",
       " '6': 7,\n",
       " '7': 8,\n",
       " '8': 9,\n",
       " '9': 10,\n",
       " 'a': 11,\n",
       " 'b': 12,\n",
       " 'c': 13,\n",
       " 'd': 14,\n",
       " 'e': 15,\n",
       " 'f': 16,\n",
       " 'g': 17,\n",
       " 'h': 18,\n",
       " 'i': 19,\n",
       " 'j': 20,\n",
       " 'k': 21,\n",
       " 'l': 22,\n",
       " 'm': 23,\n",
       " 'n': 24,\n",
       " 'o': 25,\n",
       " 'p': 26,\n",
       " 'q': 27,\n",
       " 'r': 28,\n",
       " 's': 29,\n",
       " 't': 30,\n",
       " 'u': 31,\n",
       " 'v': 32,\n",
       " 'w': 33,\n",
       " 'x': 34,\n",
       " 'y': 35,\n",
       " 'z': 36}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars =  [\".\"] + sorted(list(set(''.join(filtered_passwords))))\n",
    "stoi = {s:i for i,s in enumerate(chars)}\n",
    "itos = {i: ch for ch, i in stoi.items()}\n",
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cef82104-c8dc-4fcf-97c4-7bc6dc2f8b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 4  # context length: how many characters do we take to predict the next one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eab5e50b-d16a-4174-bc00-d10937f0fd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data setup -  function generalization based on context length\n",
    "def create_sequences(set_size,seq_length):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for password in filtered_passwords[:set_size]:\n",
    "        password = '.' + password + '.'\n",
    "        for i in range(len(password) - seq_length):\n",
    "            input_seq = password[i:i + seq_length]\n",
    "            target_char = password[i + seq_length]\n",
    "            inputs.append([stoi[char] for char in input_seq])\n",
    "            targets.append(stoi[target_char])\n",
    "    return np.array(inputs), np.array(targets)\n",
    "\n",
    "\n",
    "X_train, y_train = create_sequences(50000,seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3d1ca47-b820-474b-8771-58a4a15b4e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "input_size = len(chars)  # Number of unique characters\n",
    "hidden_size = 256\n",
    "output_size = len(chars)  \n",
    "num_epochs = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abcea9e3-3465-4318-b184-3be988b990af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10696\\3888055159.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train,dtype=torch.long)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10696\\3888055159.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train = torch.tensor(y_train)\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.tensor(X_train,dtype=torch.long)\n",
    "y_train = torch.tensor(y_train)\n",
    "X_one_hot = F.one_hot(X_train, num_classes=input_size).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29298745-b1ef-4d11-b268-0a0b5afadd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)  # out shape: (batch_size, seq_length, hidden_size)\n",
    "        out = self.fc(out[:, -1, :])  # Get the output of the last time step\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b7767c1-c1a0-4fc5-8d80-586eea3777d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "413aa88b-6871-454a-9784-0ce5d44fcbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_one_hot = X_one_hot.to(device)\n",
    "y_train = y_train.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "276c05b7-953d-40d9-9db6-93fd40bc69e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleRNN(input_size, hidden_size, output_size)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9335a9b-a3a2-4890-b241-9c0c22e47a5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"nll_loss_forward_reduce_cuda_kernel_2d_index\" not implemented for 'Int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m     19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(batch_inputs)\n\u001b[1;32m---> 20\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_labels)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[0;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1293\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mcross_entropy(\n\u001b[0;32m   1294\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1295\u001b[0m         target,\n\u001b[0;32m   1296\u001b[0m         weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m   1297\u001b[0m         ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index,\n\u001b[0;32m   1298\u001b[0m         reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction,\n\u001b[0;32m   1299\u001b[0m         label_smoothing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_smoothing,\n\u001b[0;32m   1300\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\functional.py:3479\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3478\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mcross_entropy_loss(\n\u001b[0;32m   3480\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   3481\u001b[0m     target,\n\u001b[0;32m   3482\u001b[0m     weight,\n\u001b[0;32m   3483\u001b[0m     _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction),\n\u001b[0;32m   3484\u001b[0m     ignore_index,\n\u001b[0;32m   3485\u001b[0m     label_smoothing,\n\u001b[0;32m   3486\u001b[0m )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: \"nll_loss_forward_reduce_cuda_kernel_2d_index\" not implemented for 'Int'"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_one_hot)\n",
    "    loss = criterion(outputs, y_train)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f3985e-28bc-48c5-a573-e4a8909a9eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_password(model, start_sequence, max_length=20):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # No need to track gradients\n",
    "        current_sequence = start_sequence\n",
    "        generated_password = start_sequence\n",
    "\n",
    "        for _ in range(max_length):\n",
    "            # Prepare input\n",
    "            x = torch.tensor([[stoi[c] for c in current_sequence]], dtype=torch.long)\n",
    "            x_one_hot = F.one_hot(x, num_classes=input_size).float()\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(x_one_hot)\n",
    "            \n",
    "            # Get probabilities\n",
    "            probs = F.softmax(output, dim=1)\n",
    "            \n",
    "            # Sample next character\n",
    "            next_char_index = torch.multinomial(probs, 1).item()\n",
    "            next_char = itos[next_char_index]\n",
    "            \n",
    "            # Stop if we generate the end token\n",
    "            if next_char == '.':\n",
    "                break\n",
    "            \n",
    "            # Add to generated password and update current sequence\n",
    "            generated_password += next_char\n",
    "            current_sequence = current_sequence[1:] + next_char\n",
    "\n",
    "    return generated_password[1:]  # Remove the start token\n",
    "\n",
    "# Example usage:\n",
    "start_sequence = '.kyl'  # Start with a context of seq_length\n",
    "for i in range(10):   \n",
    "    generated_password = generate_password(model, start_sequence)\n",
    "    print(generated_password)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15a1620-3eb1-4a14-9f73-3acc1ab63f48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
